{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cde35a2d-dac9-459b-b7c3-89e413c1d342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mode = 'TEST'\n",
    "%pip install pymysql\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import psycopg2\n",
    "import smtplib as smtp\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.utils import formataddr\n",
    "from email.header import Header\n",
    "from email.mime.application import MIMEApplication\n",
    "from openpyxl import load_workbook\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "115839ae-c878-4e26-92c0-fae41c9c7c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir(r'/Workspace/Ops Analysis/Reports/745 express')\n",
    "# Current datetime\n",
    "now = datetime.datetime.now()\n",
    "# Define date/time variables\n",
    "TODAY = datetime.datetime.today().strftime('%Y%m%d')\n",
    "YESTERDAY = datetime.date.today() - datetime.timedelta(days=1)\n",
    "YESTERDAY_STR = YESTERDAY.strftime('%m/%d/%Y')\n",
    "YEST = YESTERDAY.strftime('%Y-%m-%d')\n",
    "LOG_FILE_NAME = os.getcwd() + r'/logs/' + datetime.datetime.today().strftime('%Y%m%d %H%M%S') + '.log'\n",
    "CSV_FLDR = os.getcwd() + r'/CSV/'\n",
    "SQL_FLDR = os.getcwd() + r'/SQL/'\n",
    "EXCEL_FLDR = os.getcwd() + r'/XLSX/'\n",
    "# SQL file paths\n",
    "UA_SQL_1 = SQL_FLDR + r'UA_SQL_1.sql'\n",
    "CNXL_SQL_2 = SQL_FLDR + r'CNXL_SQL_2.sql'\n",
    "RES_CNXL_SQL_3 = SQL_FLDR + r'RES_CNXL_SQL_3.sql'\n",
    "SCH_DEP_SQL_4 = SQL_FLDR + r'SCH_DEP_SQL_4.sql'\n",
    "DIVERTS_SQL_5 = SQL_FLDR + r'DIVERTS_SQL_5.sql'\n",
    "RECOVERED_DIVERTS_SQL_6 = SQL_FLDR + r'RECOVERED_DIVERTS_SQL_6.sql'\n",
    "UA_HUB_SQL_7 = SQL_FLDR + r'UA_HUB_SQL_7.sql'\n",
    "FLIGHTS_NOT_DEPARTED_SQL_8 = SQL_FLDR + r'FLIGHTS_NOT_DEPARTED_SQL_8.sql'\n",
    "CANCELLED_FLIGHTS_SQL_9 = SQL_FLDR + r'Cancelled_flights_SQL_9.sql'\n",
    "YET_TO_DEPART_SQL_10 = SQL_FLDR + r'Yet_to_Depart_flights_SQL_10.sql'\n",
    "RESIDUAL_CANCELS_SQL_11 = SQL_FLDR + r'Residual_cancels_SQL_11.sql'\n",
    "REPOSITIONED_FLIGHTS_SQL_12 = SQL_FLDR + r'REPOSITIONED_FLIGHTS_SQL_12.sql'\n",
    "REPOSITIONED_COUNT_SQL_13 = SQL_FLDR + r'REPOSITIONED_FLIGHTS_COUNT_SQL_13.sql'\n",
    "DIVERTED_FLIGHTS_SQL_14 = SQL_FLDR + r'Diverted_flights_SQL_14.sql'\n",
    "DELAYS_SQL = SQL_FLDR + r'Delay_Info.sql'\n",
    "UA_2019_SQL = SQL_FLDR + r'UA_SQL_1_2019.sql'\n",
    "DIVERTS_2019_SQL = SQL_FLDR + r'DIVERTS_SQL_5_2019.sql'\n",
    "RECOVERED_2019_SQL = SQL_FLDR + r'RECOVERED_DIVERTS_2019.sql'\n",
    "UA_L7D_SQL = SQL_FLDR + r'UA_L7D.sql'\n",
    "UA_LINE_SQL = SQL_FLDR + r'UA_Line.sql'\n",
    "UA_SEAT_CANCELS_SQL = SQL_FLDR + r'UA_Seat_cancels.sql'\n",
    "UA_SEATCNXL_2019_SQL = SQL_FLDR + r'UA_SeatCnxl_2019.sql'\n",
    "# MasFlight SQL files\n",
    "OA_SQL_1 = SQL_FLDR + r'OA_SQL_1.sql'\n",
    "OA_SQL_2 = SQL_FLDR + r'OA_SQL_2.sql'\n",
    "OA_LINE_SQL = SQL_FLDR + r'OA_Line.sql'\n",
    "OA_SEATCNXL_SQL = SQL_FLDR + r'OA_SeatCnxl.sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62c9fb79-18cd-400f-827a-9517150b186d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Excel template and output paths\n",
    "EXCEL_TEMPLATE_SUMMARY = os.getcwd() + r'/0745_UAX_WB.xlsm'\n",
    "EXCEL_OUTPUT_SUMMARY = EXCEL_FLDR + '0745_UAX_WB_' + TODAY + '.xlsm'\n",
    "\n",
    "EXCEL_TEMPLATE_FLIGHTS = os.getcwd() + r'/template.xlsx'\n",
    "EXCEL_OUTPUT_FLIGHTS =  r'latest.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "# Email distribution setup\n",
    "if mode == 'PROD':\n",
    "    listEmailTo = ['harmanpreet.singh@united.com']\n",
    "    listEmailCc = []\n",
    "    listEmailBcc = []\n",
    "else:\n",
    "    listEmailTo = ['harmanpreet.singh@united.com']\n",
    "    listEmailCc = []\n",
    "    listEmailBcc = []\n",
    "\n",
    "logging.info('Starting 745 Express Report Process')\n",
    "print('Starting 745 Express Report Process')\n",
    "\n",
    "# Database credentials for UDH\n",
    "udh_username = 'app_noc_daily_ops_call'\n",
    "udh_pass = 'SBhe09r7h20gsav'\n",
    "\n",
    "# Connect to UDH (Redshift)\n",
    "logging.info('Connecting to UDH')\n",
    "print('Connecting to UDH')\n",
    "\n",
    "try:\n",
    "    udh_connection = psycopg2.connect(\n",
    "        user=udh_username,\n",
    "        password=udh_pass,\n",
    "        host='cbs-udh-datalake-prod-redshift-dw1.csjkuisl0oi7.us-east-1.redshift.amazonaws.com',\n",
    "        dbname='udhprod',\n",
    "        port=5439\n",
    "    )\n",
    "    logging.info('UDH connection successful')\n",
    "except Exception as e:\n",
    "    logging.error(f'UDH connection failed: {str(e)}')\n",
    "    raise\n",
    "\n",
    "# Check SuperSnapshot data availability\n",
    "logging.info('Checking SuperSnapshot data availability')\n",
    "print('Checking SuperSnapshot data availability')\n",
    "\n",
    "SS_CNT = pd.read_sql_query(\n",
    "    'select count(*) as cnt from co_prod_vmdb.rtf_flt_leg_operation_ss where report_dt = current_date-1',\n",
    "    udh_connection\n",
    ")\n",
    "SS_CNT_value = SS_CNT['cnt'][0]\n",
    "logging.info(f'Number of rows in SuperSnapshot: {SS_CNT_value}')\n",
    "\n",
    "if SS_CNT_value < 1000:\n",
    "    logging.warning('Latest data unavailable in UDH, checking previous day')\n",
    "    SS_CNT = pd.read_sql_query(\n",
    "        'select count(*) as cnt from co_prod_vmdb.rtf_flt_leg_operation_ss where report_dt = current_date-2',\n",
    "        udh_connection\n",
    "    )\n",
    "    SS_CNT_value = SS_CNT['cnt'][0]\n",
    "    \n",
    "    if SS_CNT_value < 1000:\n",
    "        error_msg = 'Latest data unavailable in UDH for both days'\n",
    "        logging.error(error_msg)\n",
    "        raise Exception(error_msg)\n",
    "\n",
    "logging.info('SuperSnapshot data available, proceeding with queries')\n",
    "print('SuperSnapshot data available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7b20979-edb0-4d0d-a8ce-4ca74663ea01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to clean and read SQL files\n",
    "def read_sql_file(file_path):\n",
    "    \"\"\"Read SQL file content\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "# Function to execute query and strip whitespace\n",
    "def clean_and_execute(query, connection, query_name):\n",
    "    \"\"\"Execute query and strip whitespace from string columns\"\"\"\n",
    "    result = pd.read_sql_query(query, connection)\n",
    "    result = result.apply(lambda x: x.astype(str).str.strip() if x.dtype == \"object\" else x)\n",
    "    logging.info(f'{query_name} completed - {len(result)} rows')\n",
    "    print(f'{query_name} done - {len(result)} rows')\n",
    "    return result\n",
    "\n",
    "# Read and execute UDH queries\n",
    "logging.info('Running UDH SQL queries')\n",
    "print('Running UDH SQL queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5984473-198a-4a6a-a5f0-5a59ff8c86f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ua_sql_1_df = clean_and_execute(read_sql_file(UA_SQL_1), udh_connection, 'UA_SQL_1')\n",
    "cnxl_sql_2_df = clean_and_execute(read_sql_file(CNXL_SQL_2), udh_connection, 'CNXL_SQL_2')\n",
    "res_cnxl_sql_3_df = clean_and_execute(read_sql_file(RES_CNXL_SQL_3), udh_connection, 'RES_CNXL_SQL_3')\n",
    "sch_dep_sql_4_df = clean_and_execute(read_sql_file(SCH_DEP_SQL_4), udh_connection, 'SCH_DEP_SQL_4')\n",
    "diverts_sql_5_df = clean_and_execute(read_sql_file(DIVERTS_SQL_5), udh_connection, 'DIVERTS_SQL_5')\n",
    "recovered_diverts_sql_6_df = clean_and_execute(read_sql_file(RECOVERED_DIVERTS_SQL_6), udh_connection, 'RECOVERED_DIVERTS_SQL_6')\n",
    "ua_hub_sql_7_df = clean_and_execute(read_sql_file(UA_HUB_SQL_7), udh_connection, 'UA_HUB_SQL_7')\n",
    "flights_not_departed_sql_8_df = clean_and_execute(read_sql_file(FLIGHTS_NOT_DEPARTED_SQL_8), udh_connection, 'FLIGHTS_NOT_DEPARTED_SQL_8')\n",
    "cancelled_flights_sql_9_df = clean_and_execute(read_sql_file(CANCELLED_FLIGHTS_SQL_9), udh_connection, 'CANCELLED_FLIGHTS_SQL_9')\n",
    "yet_to_depart_sql_10_df = clean_and_execute(read_sql_file(YET_TO_DEPART_SQL_10), udh_connection, 'YET_TO_DEPART_SQL_10')\n",
    "residual_cancels_sql_11_df = clean_and_execute(read_sql_file(RESIDUAL_CANCELS_SQL_11), udh_connection, 'RESIDUAL_CANCELS_SQL_11')\n",
    "repositioned_flights_sql_12_df = clean_and_execute(read_sql_file(REPOSITIONED_FLIGHTS_SQL_12), udh_connection, 'REPOSITIONED_FLIGHTS_SQL_12')\n",
    "repositioned_count_sql_13_df = clean_and_execute(read_sql_file(REPOSITIONED_COUNT_SQL_13), udh_connection, 'REPOSITIONED_COUNT_SQL_13')\n",
    "diverted_flights_sql_14_df = clean_and_execute(read_sql_file(DIVERTED_FLIGHTS_SQL_14), udh_connection, 'DIVERTED_FLIGHTS_SQL_14')\n",
    "delays_df = clean_and_execute(read_sql_file(DELAYS_SQL), udh_connection, 'DELAYS')\n",
    "ua_2019_df = clean_and_execute(read_sql_file(UA_2019_SQL), udh_connection, 'UA_2019')\n",
    "diverts_2019_df = clean_and_execute(read_sql_file(DIVERTS_2019_SQL), udh_connection, 'DIVERTS_2019')\n",
    "recovered_2019_df = clean_and_execute(read_sql_file(RECOVERED_2019_SQL), udh_connection, 'RECOVERED_2019')\n",
    "ua_l7d_df = clean_and_execute(read_sql_file(UA_L7D_SQL), udh_connection, 'UA_L7D')\n",
    "ua_line_df = clean_and_execute(read_sql_file(UA_LINE_SQL), udh_connection, 'UA_LINE')\n",
    "ua_seat_cancels_df = clean_and_execute(read_sql_file(UA_SEAT_CANCELS_SQL), udh_connection, 'UA_SEAT_CANCELS')\n",
    "ua_seatcnxl_2019_df = clean_and_execute(read_sql_file(UA_SEATCNXL_2019_SQL), udh_connection, 'UA_SEATCNXL_2019')\n",
    "\n",
    "# Connect to MasFlight and query data\n",
    "logging.info('Querying MasFlight Data')\n",
    "print('Querying MasFlight Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48dd1224-0ef8-4cec-9655-3be8891e9082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mf_connection_string = \"mysql+pymysql://ua_sumit_sharma1:uukexRCsHyAb9kw6rcMX@54.163.228.37:3306/masflightdb_customers_prd?charset=utf8mb4\"\n",
    "mf_engine = create_engine(mf_connection_string)\n",
    "\n",
    "oa_sql_1_df = clean_and_execute(read_sql_file(OA_SQL_1), mf_engine, 'OA_SQL_1')\n",
    "oa_sql_2_df = clean_and_execute(read_sql_file(OA_SQL_2), mf_engine, 'OA_SQL_2')\n",
    "oa_line_df = clean_and_execute(read_sql_file(OA_LINE_SQL), mf_engine, 'OA_LINE')\n",
    "oa_seatcnxl_df = clean_and_execute(read_sql_file(OA_SEATCNXL_SQL), mf_engine, 'OA_SEATCNXL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9aad1bf-ebea-4721-8086-596c4a78482b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to update Excel template (Using reference code pattern)\n",
    "# Function to update Excel template (Using reference code pattern)\n",
    "def update_excel_template(template_path, output_path, sheet_data_map, keep_vba=False):\n",
    "    \"\"\"\n",
    "    Opens template, clears/creates sheets, writes dataframes, and saves to new file\n",
    "    Following the pattern from UAX Scorecard reference code\n",
    "    \n",
    "    Args:\n",
    "        template_path: Path to the template Excel file\n",
    "        output_path: Path where the output file will be saved\n",
    "        sheet_data_map: Dictionary mapping sheet names to dataframes\n",
    "        keep_vba: Boolean - True for .xlsm files, False for .xlsx files\n",
    "    \"\"\"\n",
    "    logging.info(f'Loading Excel template: {template_path}')\n",
    "    print(f'Loading Excel template: {os.path.basename(template_path)}')\n",
    "    \n",
    "    # Load workbook with appropriate VBA setting\n",
    "    if keep_vba:\n",
    "        wb = load_workbook(template_path, keep_vba=True)\n",
    "    else:\n",
    "        wb = load_workbook(template_path)\n",
    "    \n",
    "    def write_df_to_sheet(wb, sheet_name, df):\n",
    "        \"\"\"Clears existing sheet (if any) and writes DataFrame content.\"\"\"\n",
    "        if sheet_name in wb.sheetnames:\n",
    "            wb.remove(wb[sheet_name])\n",
    "            logging.info(f\"{sheet_name} sheet existed and was removed\")\n",
    "\n",
    "        ws = wb.create_sheet(sheet_name)\n",
    "        logging.info(f\"{sheet_name} sheet created\")\n",
    "\n",
    "        # Write header\n",
    "        for col_idx, col_name in enumerate(df.columns, start=1):\n",
    "            ws.cell(row=1, column=col_idx, value=col_name)\n",
    "\n",
    "        # Write data rows\n",
    "        for row_idx, row in enumerate(df.itertuples(index=False), start=2):\n",
    "            for col_idx, value in enumerate(row, start=1):\n",
    "                ws.cell(row=row_idx, column=col_idx, value=value)\n",
    "\n",
    "        logging.info(f\"{sheet_name} sheet updated with {len(df)} rows\")\n",
    "        print(f\"{sheet_name} sheet updated with {len(df)} rows\")\n",
    "    \n",
    "    # Write all dataframes\n",
    "    for sheet_name, df in sheet_data_map.items():\n",
    "        write_df_to_sheet(wb, sheet_name, df)\n",
    "    \n",
    "    # Save to new filename\n",
    "    try:\n",
    "        wb.save(output_path)\n",
    "        logging.info(f'Workbook saved: {output_path}')\n",
    "        print(f'Workbook saved: {os.path.basename(output_path)}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error saving workbook: {str(e)}')\n",
    "        raise\n",
    "\n",
    "# Remove timezone info from datetime columns\n",
    "def remove_timezone_info(sheet_data_dict):\n",
    "    \"\"\"Remove timezone info from all datetime columns in dictionary of dataframes\"\"\"\n",
    "    for df in sheet_data_dict.values():\n",
    "        for col in df.select_dtypes(include=['datetimetz']).columns:\n",
    "            df[col] = df[col].dt.tz_localize(None)\n",
    "\n",
    "# Update Summary Excel (first attachment) - .xlsm file with VBA\n",
    "logging.info('Updating Summary Excel')\n",
    "print('Updating Summary Excel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90a67d17-d443-4b70-bf4d-a95e292d9b49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summary_sheet_data = {\n",
    "    \"UA_SQL_1_2019\": ua_2019_df,\n",
    "    \"UA_L7D\": ua_l7d_df,\n",
    "    \"UA_SQL_1\": ua_sql_1_df,\n",
    "    \"OA_SQL_1\": oa_sql_1_df,\n",
    "    \"OA_SQL_2\": oa_sql_2_df,\n",
    "    \"CNXL_SQL_2\": cnxl_sql_2_df,\n",
    "    \"RES_CNXL_SQL_3\": res_cnxl_sql_3_df,\n",
    "    \"SCH_DEP_SQL_4\": sch_dep_sql_4_df,\n",
    "    \"DIVERTS_SQL_5_2019\": diverts_2019_df,\n",
    "    \"TOTAL_DIVERTS_SQL_5\": diverts_sql_5_df,\n",
    "    \"RECOVERED_DIVERTS_2019\": recovered_2019_df,\n",
    "    \"DIVERTS_RECOVERED_SQL_6\": recovered_diverts_sql_6_df,\n",
    "    \"UA_HUB_SQL_7\": ua_hub_sql_7_df,\n",
    "    \"FLIGHTS_NOT_DEPARTED_SQL_8\": flights_not_departed_sql_8_df,\n",
    "    \"REPOSITIONED_FLIGHTS_SQL_13\": repositioned_count_sql_13_df,\n",
    "    \"UA_Line\": ua_line_df,\n",
    "    \"OA_Line\": oa_line_df,\n",
    "    \"Delays_Info\": delays_df,\n",
    "    \"UA_Seat_cancels\": ua_seat_cancels_df,\n",
    "    \"UA_SeatCnxl_2019\": ua_seatcnxl_2019_df,\n",
    "    \"OA_SeatCnxl\": oa_seatcnxl_df\n",
    "}\n",
    "\n",
    "remove_timezone_info(summary_sheet_data)\n",
    "update_excel_template(EXCEL_TEMPLATE_SUMMARY, EXCEL_OUTPUT_SUMMARY, summary_sheet_data, keep_vba=True)\n",
    "\n",
    "\n",
    "# Update Flight Details Excel (second attachment)\n",
    "logging.info('Updating Flight Details Excel')\n",
    "print('Updating Flight Details Excel')\n",
    "\n",
    "flights_sheet_data = {\n",
    "    \"All_cancels\": cancelled_flights_sql_9_df,\n",
    "    \"Diverted_Flights\": diverted_flights_sql_14_df,\n",
    "    \"Yet_to_Depart\": yet_to_depart_sql_10_df,\n",
    "    \"Residual_cancels\": residual_cancels_sql_11_df,\n",
    "    \"Repositioned_Flights\": repositioned_flights_sql_12_df\n",
    "}\n",
    "\n",
    "remove_timezone_info(flights_sheet_data)\n",
    "update_excel_template(EXCEL_TEMPLATE_FLIGHTS, EXCEL_OUTPUT_FLIGHTS, flights_sheet_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "758203ca-2be1-4836-b072-488e5e1ed39f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Send Email\n",
    "logging.info('Sending email')\n",
    "print('Sending email')\n",
    "\n",
    "server = smtp.SMTP('mailout.ual.com:25')\n",
    "emailFrom = 'harmanpreet.singh@united.com'\n",
    "emailFromHdr = formataddr((str(Header(r'Harman')), emailFrom))\n",
    "\n",
    "# Create message container\n",
    "msg = MIMEMultipart()\n",
    "msg['From'] = emailFromHdr\n",
    "msg['To'] = ','.join(listEmailTo)\n",
    "msg['Cc'] = ','.join(listEmailCc)\n",
    "msg['Bcc'] = ','.join(listEmailBcc)\n",
    "msg['Subject'] = \"745 Express Report - \" + YEST\n",
    "\n",
    "htmlBdy = \"\"\"<html>\n",
    "    <head></head>\n",
    "    <body>\n",
    "    <p>Hi all,\n",
    "    <br>\n",
    "    <br>Please find attached \"745 Express Report\" as of \"\"\" + YESTERDAY_STR + \"\"\".\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>Regards,\n",
    "    <br><font size=\"3\"><strong>Harman</strong></font>\n",
    "    <br><font size=\"1\">(POWERED BY DATABRICKS)</font>\n",
    "    </p>\n",
    "    </body>\n",
    "</html>\"\"\"\n",
    "\n",
    "body = MIMEText(htmlBdy, 'html')\n",
    "msg.attach(body)\n",
    "\n",
    "# Attach Summary Excel file\n",
    "logging.info('Attaching Summary Excel')\n",
    "print('Attaching Summary Excel')\n",
    "xlsx_summary = open(EXCEL_OUTPUT_SUMMARY, 'rb').read()\n",
    "msgXlsx1 = MIMEApplication(xlsx_summary, _subtype='vnd.openxmlformats-officedocument.spreadsheetml.sheet')\n",
    "msgXlsx1.add_header('Content-ID', '<xlsx1>')\n",
    "msgXlsx1.add_header('Content-Disposition', 'attachment', filename=os.path.basename(EXCEL_OUTPUT_SUMMARY))\n",
    "msg.attach(msgXlsx1)\n",
    "\n",
    "# Attach Flight Details Excel file\n",
    "logging.info('Attaching Flight Details Excel')\n",
    "print('Attaching Flight Details Excel')\n",
    "xlsx_flights = open(EXCEL_OUTPUT_FLIGHTS, 'rb').read()\n",
    "msgXlsx2 = MIMEApplication(xlsx_flights, _subtype='vnd.openxmlformats-officedocument.spreadsheetml.sheet')\n",
    "msgXlsx2.add_header('Content-ID', '<xlsx2>')\n",
    "msgXlsx2.add_header('Content-Disposition', 'attachment', filename=os.path.basename(EXCEL_OUTPUT_FLIGHTS))\n",
    "msg.attach(msgXlsx2)\n",
    "\n",
    "server.sendmail(emailFrom, listEmailTo + listEmailCc + listEmailBcc, msg.as_bytes())\n",
    "logging.info('Email sent and process is completed')\n",
    "print('Email sent')\n",
    "server.quit()\n",
    "\n",
    "# Close connections\n",
    "udh_connection.close()\n",
    "logging.info('Process completed successfully')\n",
    "print('Process completed successfully')\n",
    "\n",
    "# Data validation\n",
    "if len(ua_sql_1_df) <= 10:\n",
    "    error_msg = 'Latest data unavailable in UDH - insufficient rows'\n",
    "    logging.error(error_msg)\n",
    "    print(error_msg)\n",
    "\n",
    "if len(oa_sql_1_df) == 0:\n",
    "    error_msg = 'Latest data unavailable in MasFlight'\n",
    "    logging.error(error_msg)\n",
    "    print(error_msg)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "745 Express",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
